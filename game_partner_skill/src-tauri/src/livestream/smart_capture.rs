/// ç›´æ’­é—´æ™ºèƒ½æˆªå›¾+è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ
/// 
/// åŠŸèƒ½ï¼š
/// 1. æŒç»­ç›‘å¬ä¸»æ’­è¯­éŸ³ï¼ˆä½¿ç”¨ä¼˜åŒ–çš„ VAD é…ç½®ï¼‰
/// 2. è¯­éŸ³å¼€å§‹æ—¶æˆªå›¾ï¼ˆè®°å½•æ¸¸æˆåˆå§‹çŠ¶æ€ï¼‰
/// 3. è¯­éŸ³ç»“æŸæ—¶æˆªå›¾ï¼ˆè®°å½•æ¸¸æˆå˜åŒ–çŠ¶æ€ï¼‰
/// 4. å°†åŒæˆªå›¾+è¯­éŸ³æ–‡æœ¬å‘é€ç»™å¤šæ¨¡æ€ AI åˆ†æ
///
/// VAD é…ç½®ä¼˜åŒ–ï¼ˆç›´æ’­é—´åœºæ™¯ï¼‰ï¼š
/// - éŸ³é‡é˜ˆå€¼ï¼š0.035ï¼ˆé¿å…æ¸¸æˆéŸ³æ•ˆè¯¯è§¦å‘ï¼‰
/// - é™éŸ³åˆ¤å®šï¼š2.5ç§’ï¼ˆå…è®¸ä¸»æ’­æ€è€ƒæš‚åœï¼‰
/// - æœ€çŸ­è¯­éŸ³ï¼š0.5ç§’ï¼ˆè¿‡æ»¤çŸ­ä¿ƒå™ªéŸ³ï¼‰
/// - æœ€é•¿è¯­éŸ³ï¼š60ç§’ï¼ˆæ”¯æŒè¿ç»­è®²è§£ï¼‰

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};
use tokio::sync::mpsc;
use tokio::task::JoinHandle;
use tauri::{AppHandle, Emitter, Manager};

use crate::audio::{
    continuous_listener::ContinuousListener,
    recorder::RecorderConfig,
    vad::VadConfig,
};
use crate::screenshot::Screenshot;
use crate::commands::screen_commands::ScreenshotState;

/// æ™ºèƒ½æˆªå›¾äº‹ä»¶
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type")]
pub enum SmartCaptureEvent {
    /// å¼€å§‹è¯´è¯ï¼ˆå·²æˆªå›¾ï¼‰
    SpeechStarted {
        screenshot_start: Screenshot,
        timestamp: u64,
    },
    /// ç»“æŸè¯´è¯ï¼ˆå·²æˆªå›¾+è¯†åˆ«ï¼‰
    SpeechEnded {
        screenshot_start: Screenshot,
        screenshot_end: Screenshot,
        transcription: String,
        duration_secs: f32,
        timestamp: u64,
    },
    /// è¯†åˆ«å¤±è´¥
    RecognitionFailed {
        screenshot_start: Screenshot,
        screenshot_end: Screenshot,
        error: String,
        timestamp: u64,
    },
    /// é”™è¯¯
    Error {
        message: String,
    },
}

/// ç›´æ’­é—´æ™ºèƒ½æˆªå›¾é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SmartCaptureConfig {
    /// æˆªå›¾æ¨¡å¼ï¼ˆ"window" æˆ– "fullscreen"ï¼‰
    pub capture_mode: String,
    /// ç›®æ ‡çª—å£ IDï¼ˆçª—å£æ¨¡å¼æ—¶ä½¿ç”¨ï¼‰
    pub target_window_id: Option<u32>,
    /// æ˜¯å¦å¯ç”¨åŒæˆªå›¾
    pub enable_dual_screenshot: bool,
    /// VAD é…ç½®
    pub vad_config: VadConfigDto,
}

impl Default for SmartCaptureConfig {
    fn default() -> Self {
        Self {
            capture_mode: "fullscreen".to_string(),
            target_window_id: None,
            enable_dual_screenshot: true,
            vad_config: VadConfigDto::livestream_optimized(),
        }
    }
}

/// VAD é…ç½® DTOï¼ˆç”¨äºå‰ç«¯é€šä¿¡ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VadConfigDto {
    pub volume_threshold: f32,
    pub silence_duration_secs: f32,
    pub min_speech_duration_secs: f32,
    pub max_speech_duration_secs: f32,
}

impl VadConfigDto {
    /// ç›´æ’­é—´ä¼˜åŒ–é…ç½®
    pub fn livestream_optimized() -> Self {
        Self {
            volume_threshold: 0.035,          // é¿å…æ¸¸æˆéŸ³æ•ˆè¯¯è§¦å‘
            silence_duration_secs: 2.5,       // å…è®¸ä¸»æ’­æ€è€ƒæš‚åœ
            min_speech_duration_secs: 0.5,    // è¿‡æ»¤çŸ­ä¿ƒå™ªéŸ³
            max_speech_duration_secs: 60.0,   // æ”¯æŒè¿ç»­è®²è§£
        }
    }
}

impl From<VadConfigDto> for VadConfig {
    fn from(dto: VadConfigDto) -> Self {
        VadConfig {
            volume_threshold: dto.volume_threshold,
            silence_duration_secs: dto.silence_duration_secs,
            min_speech_duration_secs: dto.min_speech_duration_secs,
            max_speech_duration_secs: dto.max_speech_duration_secs,
            rms_window_size: 1024, // å›ºå®šå€¼
        }
    }
}

/// æ™ºèƒ½æˆªå›¾ç®¡ç†å™¨
pub struct SmartCaptureManager {
    app: AppHandle,
    config: SmartCaptureConfig,
    
    /// è¯­éŸ³ç›‘å¬å™¨
    listener: Option<ContinuousListener>,
    
    /// å½“å‰ä¼šè¯çš„å¼€å§‹æˆªå›¾ï¼ˆä¸´æ—¶å­˜å‚¨ï¼‰
    current_screenshot_start: Arc<Mutex<Option<Screenshot>>>,
    
    /// æ˜¯å¦æ­£åœ¨è¿è¡Œ
    is_running: Arc<Mutex<bool>>,
    
    /// ç›‘å¬ä»»åŠ¡å¥æŸ„
    listen_task: Option<JoinHandle<()>>,
}

impl SmartCaptureManager {
    /// åˆ›å»ºæ–°çš„æ™ºèƒ½æˆªå›¾ç®¡ç†å™¨
    pub fn new(app: AppHandle, config: SmartCaptureConfig) -> Self {
        Self {
            app,
            config,
            listener: None,
            current_screenshot_start: Arc::new(Mutex::new(None)),
            is_running: Arc::new(Mutex::new(false)),
            listen_task: None,
        }
    }

    /// å¼€å§‹æ™ºèƒ½æˆªå›¾+è¯­éŸ³è¯†åˆ«
    pub async fn start(&mut self) -> Result<()> {
        // æ£€æŸ¥æ˜¯å¦å·²è¿è¡Œ
        {
            let mut running = self.is_running.lock().unwrap();
            if *running {
                return Err(anyhow::anyhow!("æ™ºèƒ½æˆªå›¾å·²åœ¨è¿è¡Œä¸­"));
            }
            *running = true;
        }

        log::info!("ğŸ¬ å¯åŠ¨ç›´æ’­é—´æ™ºèƒ½æˆªå›¾ç³»ç»Ÿ");
        log::info!("ğŸ“‹ VAD é…ç½®: éŸ³é‡é˜ˆå€¼={}, é™éŸ³åˆ¤å®š={}ç§’, æœ€çŸ­è¯­éŸ³={}ç§’, æœ€é•¿è¯­éŸ³={}ç§’",
                  self.config.vad_config.volume_threshold,
                  self.config.vad_config.silence_duration_secs,
                  self.config.vad_config.min_speech_duration_secs,
                  self.config.vad_config.max_speech_duration_secs);

        // åˆ›å»ºè¯­éŸ³ç›‘å¬å™¨
        let vad_config: VadConfig = self.config.vad_config.clone().into();
        let recorder_config = RecorderConfig::default();
        let mut listener = ContinuousListener::new(vad_config, recorder_config);

        // è®¾ç½®äº‹ä»¶å›è°ƒ
        let app = self.app.clone();
        let config = self.config.clone();
        let screenshot_start_ref = Arc::clone(&self.current_screenshot_start);

        listener.start_listening(move |event| {
            let app = app.clone();
            let config = config.clone();
            let screenshot_start_ref = screenshot_start_ref.clone();

            // åœ¨ tokio runtime ä¸­å¤„ç†äº‹ä»¶
            tokio::spawn(async move {
                if let Err(e) = Self::handle_listener_event(
                    &app,
                    &config,
                    screenshot_start_ref,
                    event,
                ).await {
                    log::error!("âŒ å¤„ç†ç›‘å¬å™¨äº‹ä»¶å¤±è´¥: {}", e);
                }
            });
        })?;

        self.listener = Some(listener);
        
        log::info!("âœ… æ™ºèƒ½æˆªå›¾ç³»ç»Ÿå·²å¯åŠ¨");
        Ok(())
    }

    /// åœæ­¢æ™ºèƒ½æˆªå›¾+è¯­éŸ³è¯†åˆ«
    pub fn stop(&mut self) -> Result<()> {
        log::info!("â¹ï¸ åœæ­¢ç›´æ’­é—´æ™ºèƒ½æˆªå›¾ç³»ç»Ÿ");

        // æ ‡è®°ä¸ºæœªè¿è¡Œ
        {
            let mut running = self.is_running.lock().unwrap();
            *running = false;
        }

        // åœæ­¢ç›‘å¬å™¨
        if let Some(mut listener) = self.listener.take() {
            listener.stop_listening()?;
        }

        // æ¸…ç†ä¸´æ—¶æˆªå›¾
        {
            let mut screenshot = self.current_screenshot_start.lock().unwrap();
            *screenshot = None;
        }

        log::info!("âœ… æ™ºèƒ½æˆªå›¾ç³»ç»Ÿå·²åœæ­¢");
        Ok(())
    }

    /// å¤„ç†ç›‘å¬å™¨äº‹ä»¶
    async fn handle_listener_event(
        app: &AppHandle,
        config: &SmartCaptureConfig,
        screenshot_start_ref: Arc<Mutex<Option<Screenshot>>>,
        event: crate::audio::continuous_listener::ListenerEvent,
    ) -> Result<()> {
        use crate::audio::continuous_listener::ListenerEvent;

        match event {
            ListenerEvent::SpeechStarted => {
                log::info!("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ï¼Œæ‰§è¡Œç¬¬ä¸€æ¬¡æˆªå›¾...");
                
                // æˆªå›¾
                match Self::capture_screenshot(app, config).await {
                    Ok(screenshot) => {
                        log::info!("ğŸ“¸ å¼€å§‹æˆªå›¾æˆåŠŸ: {}x{}", screenshot.width, screenshot.height);
                        
                        // ä¿å­˜åˆ°ä¸´æ—¶å­˜å‚¨
                        {
                            let mut current = screenshot_start_ref.lock().unwrap();
                            *current = Some(screenshot.clone());
                        }

                        // å‘é€äº‹ä»¶åˆ°å‰ç«¯
                        let event = SmartCaptureEvent::SpeechStarted {
                            screenshot_start: screenshot,
                            timestamp: chrono::Utc::now().timestamp() as u64,
                        };
                        let _ = app.emit("smart_capture_event", event);
                    }
                    Err(e) => {
                        log::error!("âŒ å¼€å§‹æˆªå›¾å¤±è´¥: {}", e);
                    }
                }
            }

            ListenerEvent::SpeechEnded { duration_secs } => {
                log::info!("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ ({:.1}ç§’)ï¼Œæ‰§è¡Œç¬¬äºŒæ¬¡æˆªå›¾...", duration_secs);
                
                // æˆªå›¾
                match Self::capture_screenshot(app, config).await {
                    Ok(screenshot_end) => {
                        log::info!("ğŸ“¸ ç»“æŸæˆªå›¾æˆåŠŸ: {}x{}", screenshot_end.width, screenshot_end.height);
                        
                        // è·å–å¼€å§‹æˆªå›¾
                        let screenshot_start = {
                            let mut current = screenshot_start_ref.lock().unwrap();
                            current.take()
                        };

                        if let Some(screenshot_start) = screenshot_start {
                            log::info!("âœ… åŒæˆªå›¾å‡†å¤‡å®Œæˆï¼Œç­‰å¾…è¯­éŸ³è¯†åˆ«ç»“æœ...");
                            // æ³¨æ„ï¼šè¯­éŸ³è¯†åˆ«ç»“æœä¼šåœ¨ AliyunRecognizeRequest äº‹ä»¶ä¸­å¤„ç†
                            // è¿™é‡Œæš‚æ—¶ä¸å‘é€äº‹ä»¶ï¼Œç­‰å¾…è¯†åˆ«å®Œæˆ
                            
                            // ä¸´æ—¶å­˜å‚¨ç»“æŸæˆªå›¾ï¼Œç­‰å¾…è¯†åˆ«ç»“æœ
                            // TODO: éœ€è¦åœ¨ AliyunRecognizeRequest äº‹ä»¶ä¸­è·å–è¿™ä¸¤å¼ æˆªå›¾
                        } else {
                            log::warn!("âš ï¸ æœªæ‰¾åˆ°å¼€å§‹æˆªå›¾ï¼Œè·³è¿‡æœ¬æ¬¡åŒæˆªå›¾");
                        }
                    }
                    Err(e) => {
                        log::error!("âŒ ç»“æŸæˆªå›¾å¤±è´¥: {}", e);
                    }
                }
            }

            ListenerEvent::AliyunRecognizeRequest { pcm_data, sample_rate, duration_secs } => {
                log::info!("ğŸ¯ æ”¶åˆ°é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚: {} å­—èŠ‚, {}Hz, {:.1}ç§’",
                          pcm_data.len(), sample_rate, duration_secs);
                
                // å‘é€äº‹ä»¶åˆ°å‰ç«¯ï¼Œå‰ç«¯ä¼šè°ƒç”¨ aliyun_one_sentence_recognize
                let payload = serde_json::json!({
                    "pcm_data": pcm_data,
                    "sample_rate": sample_rate,
                    "duration_secs": duration_secs,
                });
                let _ = app.emit("livestream_recognize_request", payload);
            }

            ListenerEvent::VoiceTranscribed { text } => {
                log::info!("ğŸ“ è¯­éŸ³è¯†åˆ«å®Œæˆ: {}", text);
                
                // è¿™é‡Œå¯ä»¥å‘é€åŒ…å«åŒæˆªå›¾å’Œè¯†åˆ«ç»“æœçš„äº‹ä»¶
                // TODO: å®ç°å®Œæ•´çš„äº‹ä»¶å‘é€é€»è¾‘
            }

            ListenerEvent::Error { message } => {
                log::error!("âŒ ç›‘å¬å™¨é”™è¯¯: {}", message);
                let event = SmartCaptureEvent::Error { message };
                let _ = app.emit("smart_capture_event", event);
            }

            _ => {
                // å…¶ä»–äº‹ä»¶å¿½ç•¥
            }
        }

        Ok(())
    }

    /// æ‰§è¡Œæˆªå›¾
    async fn capture_screenshot(
        app: &AppHandle,
        config: &SmartCaptureConfig,
    ) -> Result<Screenshot> {
        // ä» Tauri State è·å– ScreenshotState
        let screenshot_state: tauri::State<ScreenshotState> = app.state();

        match config.capture_mode.as_str() {
            "window" => {
                // çª—å£æˆªå›¾
                if let Some(window_id) = config.target_window_id {
                    log::debug!("ğŸªŸ æ•è·çª—å£ ID: {}", window_id);
                    crate::screenshot::capture_window(window_id)
                        .context("çª—å£æˆªå›¾å¤±è´¥")
                } else {
                    log::warn!("âš ï¸ çª—å£æ¨¡å¼ä½†æœªè®¾ç½®çª—å£ IDï¼Œå›é€€åˆ°å…¨å±æˆªå›¾");
                    let capturer = screenshot_state.get_or_init()
                        .context("åˆå§‹åŒ–æˆªå›¾å™¨å¤±è´¥")?;
                    capturer.capture_fullscreen(None)
                        .context("å…¨å±æˆªå›¾å¤±è´¥")
                }
            }
            "fullscreen" | _ => {
                // å…¨å±æˆªå›¾
                log::debug!("ğŸ–¥ï¸ å…¨å±æˆªå›¾");
                let capturer = screenshot_state.get_or_init()
                    .context("åˆå§‹åŒ–æˆªå›¾å™¨å¤±è´¥")?;
                capturer.capture_fullscreen(None)
                    .context("å…¨å±æˆªå›¾å¤±è´¥")
            }
        }
    }

    /// è·å–è¿è¡ŒçŠ¶æ€
    pub fn is_running(&self) -> bool {
        *self.is_running.lock().unwrap()
    }
}
