/// AI åˆ†ææœåŠ¡
/// 
/// æ¥æ”¶ä¸»æ’­è¯­éŸ³ + åŒæˆªå›¾ + å‘˜å·¥å¯¹è¯å†å²ï¼Œè¿”å›æ™ºèƒ½åŒ–çš„å¼¹å¹•å›å¤

use serde::{Deserialize, Serialize};
use base64::{Engine as _, engine::general_purpose::STANDARD as BASE64};

/// AI åˆ†æè¯·æ±‚
#[derive(Debug, Clone, Serialize)]
pub struct AIAnalysisRequest {
    /// ä¸»æ’­è¯´çš„è¯ï¼ˆè¯­éŸ³è¯†åˆ«ç»“æœï¼‰
    pub streamer_speech: String,
    
    /// å¼€å§‹è¯´è¯æ—¶çš„æˆªå›¾ï¼ˆBase64ï¼‰
    pub screenshot_before: String,
    
    /// ç»“æŸè¯´è¯æ—¶çš„æˆªå›¾ï¼ˆBase64ï¼‰
    pub screenshot_after: String,
    
    /// å‘˜å·¥åˆ—è¡¨åŠå…¶å¯¹è¯å†å²
    pub employees: Vec<EmployeeContext>,
}

/// å‘˜å·¥ä¸Šä¸‹æ–‡ä¿¡æ¯
#[derive(Debug, Clone, Serialize)]
pub struct EmployeeContext {
    /// å‘˜å·¥ ID
    pub id: String,
    
    /// å‘˜å·¥æ˜µç§°
    pub nickname: String,
    
    /// å‘˜å·¥æ€§æ ¼
    pub personality: String,
    
    /// å¯¹è¯å†å²ï¼ˆæœ€è¿‘ 10 æ¡ï¼‰
    pub conversation_history: Vec<ConversationMessage>,
}

/// å¯¹è¯æ¶ˆæ¯
#[derive(Debug, Clone, Serialize)]
pub struct ConversationMessage {
    pub role: String,  // "user" (ä¸»æ’­) æˆ– "assistant" (å‘˜å·¥)
    pub content: String,
}

/// AI åˆ†æå“åº”
#[derive(Debug, Clone, Deserialize)]
pub struct AIAnalysisResponse {
    pub actions: Vec<EmployeeAction>,
}

/// å‘˜å·¥è¡Œä¸ºå†³ç­–
#[derive(Debug, Clone, Deserialize)]
pub struct EmployeeAction {
    /// å‘˜å·¥ ID
    pub employee: String,
    
    /// è¦å‘é€çš„å¼¹å¹•å†…å®¹
    pub content: String,
    
    /// æ˜¯å¦å‘é€ç¤¼ç‰©
    pub gift: bool,
    
    /// ç¤¼ç‰©åç§°ï¼ˆå¦‚æœ gift = trueï¼‰
    #[serde(default)]
    pub gift_name: Option<String>,
    
    /// ç¤¼ç‰©æ•°é‡ï¼ˆå¦‚æœ gift = trueï¼‰
    #[serde(default)]
    pub gift_count: Option<u32>,
}

/// AI åˆ†æå™¨
#[derive(Clone)]
pub struct AIAnalyzer {
    api_endpoint: String,
    api_key: String,
    model: String,
}

impl AIAnalyzer {
    pub fn new(api_endpoint: String, api_key: String, model: String) -> Self {
        Self {
            api_endpoint,
            api_key,
            model,
        }
    }

    /// åˆ†æä¸»æ’­è¯­éŸ³å’Œæ¸¸æˆçŠ¶æ€ï¼Œç”Ÿæˆå‘˜å·¥äº’åŠ¨å†³ç­–
    pub async fn analyze(
        &self,
        request: AIAnalysisRequest,
    ) -> Result<AIAnalysisResponse, String> {
        println!("ğŸ¤– å¼€å§‹ AI åˆ†æ...");
        println!("  ä¸»æ’­è¯´è¯: {}", request.streamer_speech);
        println!("  å‘˜å·¥æ•°é‡: {}", request.employees.len());

        // æ„å»ºæç¤ºè¯
        let prompt = self.build_prompt(&request);
        
        // æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
        let messages = vec![
            serde_json::json!({
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªç›´æ’­é—´äº’åŠ¨åˆ†æä¸“å®¶ã€‚æ ¹æ®ä¸»æ’­çš„è¯­éŸ³å’Œæ¸¸æˆç”»é¢å˜åŒ–ï¼Œä¸ºæ¯ä¸ªAIå‘˜å·¥ç”Ÿæˆè‡ªç„¶ã€æœ‰è¶£ã€ç¬¦åˆå…¶æ€§æ ¼çš„å¼¹å¹•å›å¤ã€‚ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"
            }),
            serde_json::json!({
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": format!("data:image/png;base64,{}", request.screenshot_before)
                        }
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": format!("data:image/png;base64,{}", request.screenshot_after)
                        }
                    }
                ]
            }),
        ];

        // è°ƒç”¨ LLM API
        let client = reqwest::Client::new();
        let response = client
            .post(&self.api_endpoint)
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&serde_json::json!({
                "model": self.model,
                "messages": messages,
                "temperature": 0.8,
                "max_tokens": 2000,
                "response_format": { "type": "json_object" }
            }))
            .send()
            .await
            .map_err(|e| format!("API è¯·æ±‚å¤±è´¥: {}", e))?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            return Err(format!("API è¿”å›é”™è¯¯ {}: {}", status, error_text));
        }

        let response_json: serde_json::Value = response
            .json()
            .await
            .map_err(|e| format!("è§£æå“åº”å¤±è´¥: {}", e))?;

        // æå– AI è¿”å›çš„å†…å®¹
        let content = response_json["choices"][0]["message"]["content"]
            .as_str()
            .ok_or("æ— æ³•è·å– AI å“åº”å†…å®¹")?;

        println!("âœ… AI è¿”å›: {}", content);

        // è§£æ JSON
        let ai_response: AIAnalysisResponse = serde_json::from_str(content)
            .map_err(|e| format!("è§£æ AI å“åº” JSON å¤±è´¥: {}", e))?;

        println!("âœ… AI åˆ†æå®Œæˆï¼Œç”Ÿæˆ {} ä¸ªå‘˜å·¥è¡Œä¸º", ai_response.actions.len());

        Ok(ai_response)
    }

    /// æ„å»ºæç¤ºè¯
    fn build_prompt(&self, request: &AIAnalysisRequest) -> String {
        let mut prompt = format!(
            "# ç›´æ’­é—´äº’åŠ¨åˆ†æä»»åŠ¡\n\n\
            ## ä¸»æ’­è¯­éŸ³è¯†åˆ«ç»“æœ\n\
            \"{}\"\n\n\
            ## æ¸¸æˆç”»é¢å˜åŒ–\n\
            - å›¾ç‰‡1ï¼šä¸»æ’­å¼€å§‹è¯´è¯æ—¶çš„æ¸¸æˆçŠ¶æ€\n\
            - å›¾ç‰‡2ï¼šä¸»æ’­ç»“æŸè¯´è¯æ—¶çš„æ¸¸æˆçŠ¶æ€\n\
            è¯·åˆ†ææ¸¸æˆç”»é¢ä¸­å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–ï¼ˆå¦‚è§’è‰²ç§»åŠ¨ã€æˆ˜æ–—ã€å¾—åˆ†ç­‰ï¼‰\n\n\
            ## AI å‘˜å·¥ä¿¡æ¯\n",
            request.streamer_speech
        );

        // æ·»åŠ æ¯ä¸ªå‘˜å·¥çš„ä¿¡æ¯
        for (i, employee) in request.employees.iter().enumerate() {
            prompt.push_str(&format!(
                "### å‘˜å·¥ {} - {} (æ€§æ ¼: {})\n",
                i + 1,
                employee.nickname,
                self.get_personality_description(&employee.personality)
            ));

            // æ·»åŠ å¯¹è¯å†å²
            if !employee.conversation_history.is_empty() {
                prompt.push_str("**æœ€è¿‘å¯¹è¯å†å²:**\n");
                for msg in employee.conversation_history.iter().rev().take(5).rev() {
                    let role_label = if msg.role == "user" { "ä¸»æ’­" } else { &employee.nickname };
                    prompt.push_str(&format!("- {}: {}\n", role_label, msg.content));
                }
            } else {
                prompt.push_str("*ï¼ˆæš‚æ— å¯¹è¯å†å²ï¼‰*\n");
            }
            prompt.push('\n');
        }

        // æ·»åŠ ä»»åŠ¡è¦æ±‚
        prompt.push_str(
            "## ä»»åŠ¡è¦æ±‚\n\
            1. **åˆ†æä¸»æ’­çš„è¯å’Œæ¸¸æˆç”»é¢å˜åŒ–**ï¼Œç†è§£å½“å‰çš„æ¸¸æˆè¿›å±•å’Œä¸»æ’­æƒ…ç»ª\n\
            2. **ä¸ºæ¯ä¸ªAIå‘˜å·¥å†³å®šæ˜¯å¦å‘å¼¹å¹•**ï¼ˆä¸æ˜¯æ‰€æœ‰å‘˜å·¥éƒ½è¦å›å¤ï¼Œè‡ªç„¶ä¸€ç‚¹ï¼‰\n\
            3. **ç”Ÿæˆç¬¦åˆå‘˜å·¥æ€§æ ¼çš„å¼¹å¹•å†…å®¹**ï¼ˆå‚è€ƒå¯¹è¯å†å²ï¼Œä¿æŒè¿è´¯æ€§ï¼‰\n\
            4. **åˆ¤æ–­æ˜¯å¦é€ç¤¼ç‰©**ï¼ˆç²¾å½©æ“ä½œã€èƒœåˆ©ã€é‡Œç¨‹ç¢‘æ—¶åˆ»å¯ä»¥é€ç¤¼ç‰©ï¼‰\n\n\
            ## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼ JSONï¼‰\n\
            ```json\n\
            {\n  \
              \"actions\": [\n    \
                {\n      \
                  \"employee\": \"å‘˜å·¥ID\",\n      \
                  \"content\": \"å¼¹å¹•å†…å®¹ï¼ˆ20å­—ä»¥å†…ï¼Œè‡ªç„¶å£è¯­åŒ–ï¼‰\",\n      \
                  \"gift\": false,\n      \
                  \"gift_name\": \"ğŸš€ç«ç®­\",\n      \
                  \"gift_count\": 1\n    \
                }\n  \
              ]\n\
            }\n\
            ```\n\n\
            **æ³¨æ„äº‹é¡¹:**\n\
            - å¦‚æœä¸»æ’­è¯´çš„è¯ä¸éœ€è¦å›å¤ï¼ˆå¦‚è‡ªè¨€è‡ªè¯­ã€å’•å“ï¼‰ï¼Œå¯ä»¥è¿”å›ç©ºæ•°ç»„ `[]`\n\
            - å¼¹å¹•è¦ç®€çŸ­ã€æœ‰è¶£ã€ç¬¦åˆç›´æ’­é—´æ°›å›´\n\
            - ç¤¼ç‰©åç§°å¯é€‰: ğŸš€ç«ç®­, ğŸŒ¹é²œèŠ±, 666, ğŸ’é’»çŸ³\n\
            - ä¸è¦æ‰€æœ‰å‘˜å·¥éƒ½å›å¤ï¼Œé€‰æ‹©1-3ä¸ªæœ€ç›¸å…³çš„å‘˜å·¥å³å¯\n\
            - å‚è€ƒå‘˜å·¥çš„å¯¹è¯å†å²ï¼Œé¿å…é‡å¤ç›¸ä¼¼çš„å†…å®¹\n\n\
            è¯·ç›´æ¥è¿”å› JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"
        );

        prompt
    }

    /// è·å–æ€§æ ¼æè¿°
    fn get_personality_description(&self, personality: &str) -> &'static str {
        match personality {
            "sunnyou_male" => "æŸå‹ç”·ï¼ˆå¹½é»˜è°ƒä¾ƒã€å…„å¼Ÿä¹‰æ°”ï¼‰",
            "funny_female" => "æç¬‘å¥³ï¼ˆæ´»æ³¼å¼€æœ—ã€çˆ±å¼€ç©ç¬‘ï¼‰",
            "kobe" => "ç§‘æ¯”é£æ ¼ï¼ˆåŠ±å¿—ã€ä¸“æ³¨ã€å† å†›å¿ƒæ€ï¼‰",
            "sweet_girl" => "ç”œå¦¹ï¼ˆæ¸©æŸ”å¯çˆ±ã€é¼“åŠ±æ”¯æŒï¼‰",
            "trump" => "ç‰¹æœ—æ™®é£æ ¼ï¼ˆå¤¸å¼ ã€è‡ªä¿¡ã€å£å·å¼ï¼‰",
            _ => "é»˜è®¤æ€§æ ¼",
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_prompt_building() {
        let analyzer = AIAnalyzer::new(
            "https://api.example.com/v1/chat/completions".to_string(),
            "test-key".to_string(),
            "gpt-4o".to_string(),
        );

        let request = AIAnalysisRequest {
            streamer_speech: "å“‡ï¼Œè¿™æ³¢æ“ä½œå¯ä»¥å•Šï¼".to_string(),
            screenshot_before: "base64_image_1".to_string(),
            screenshot_after: "base64_image_2".to_string(),
            employees: vec![
                EmployeeContext {
                    id: "emp1".to_string(),
                    nickname: "å°æ˜".to_string(),
                    personality: "sunnyou_male".to_string(),
                    conversation_history: vec![
                        ConversationMessage {
                            role: "user".to_string(),
                            content: "å¼€å§‹æ¸¸æˆäº†".to_string(),
                        },
                        ConversationMessage {
                            role: "assistant".to_string(),
                            content: "å†²å†²å†²ï¼".to_string(),
                        },
                    ],
                },
            ],
        };

        let prompt = analyzer.build_prompt(&request);
        assert!(prompt.contains("ç›´æ’­é—´äº’åŠ¨åˆ†æä»»åŠ¡"));
        assert!(prompt.contains("å°æ˜"));
        assert!(prompt.contains("æŸå‹ç”·"));
    }
}
