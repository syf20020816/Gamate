use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::path::PathBuf;

/// AI ç›´æ¥æ£€ç´¢ï¼ˆä¸ä½¿ç”¨å‘é‡æ•°æ®åº“ï¼‰
pub struct AIDirectSearch {
    storage_path: PathBuf,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WikiEntry {
    pub title: String,
    pub content: String,
    pub url: String,
}

impl AIDirectSearch {
    pub fn new(storage_path: PathBuf) -> Self {
        Self { storage_path }
    }

    /// åŠ è½½ JSONL æ–‡ä»¶
    pub fn load_wiki_entries(&self, game_id: &str) -> Result<Vec<WikiEntry>> {
        let jsonl_path = self.storage_path.join(format!("{}.jsonl", game_id));
        
        log::info!("ğŸ” AI ç›´æ¥æœç´¢: å°è¯•åŠ è½½æ–‡ä»¶ {:?}", jsonl_path);
        
        if !jsonl_path.exists() {
            log::warn!("âš ï¸ JSONL æ–‡ä»¶ä¸å­˜åœ¨: {:?}", jsonl_path);
            return Ok(Vec::new());
        }

        let content = std::fs::read_to_string(&jsonl_path)?;
        log::info!("ğŸ“„ æ–‡ä»¶å¤§å°: {} å­—èŠ‚, è¡Œæ•°: {}", content.len(), content.lines().count());
        
        let entries: Vec<WikiEntry> = content
            .lines()
            .filter(|line| !line.trim().is_empty())
            .filter_map(|line| {
                match serde_json::from_str::<WikiEntry>(line) {
                    Ok(entry) => Some(entry),
                    Err(e) => {
                        log::debug!("è§£æ JSON è¡Œå¤±è´¥: {}, å†…å®¹: {}", e, &line[..line.len().min(100)]);
                        None
                    }
                }
            })
            .collect();

        log::info!("âœ… æˆåŠŸåŠ è½½ {} æ¡ Wiki æ¡ç›®", entries.len());
        Ok(entries)
    }

    /// ä½¿ç”¨ AI è¿›è¡Œæ£€ç´¢ï¼ˆç®€åŒ–ç‰ˆï¼šå…³é”®è¯åŒ¹é… + æ–‡æœ¬ç›¸ä¼¼åº¦ï¼‰
    /// æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–å®ç°ï¼ŒçœŸæ­£çš„ AI æ£€ç´¢éœ€è¦è°ƒç”¨ LLM
    pub fn search(&self, query: &str, game_id: &str, limit: usize) -> Result<Vec<SearchResult>> {
        let entries = self.load_wiki_entries(game_id)?;
        
        if entries.is_empty() {
            log::warn!("âš ï¸ æ²¡æœ‰å¯æœç´¢çš„æ¡ç›®");
            return Ok(Vec::new());
        }

        log::info!("ğŸ” å¼€å§‹æœç´¢: query='{}', æ¡ç›®æ•°={}", query, entries.len());
        
        let query_lower = query.to_lowercase();
        let query_words: Vec<&str> = query_lower.split_whitespace().collect();
        
        log::debug!("æŸ¥è¯¢è¯: {:?}", query_words);

        // è®¡ç®—æ¯ä¸ªæ¡ç›®çš„ç›¸å…³æ€§åˆ†æ•°
        let mut scored_entries: Vec<(f32, WikiEntry)> = entries
            .into_iter()
            .map(|entry| {
                let score = calculate_relevance_score(&entry, &query_lower, &query_words);
                if score > 0.0 {
                    log::debug!("åŒ¹é…: '{}' åˆ†æ•°={}", entry.title, score);
                }
                (score, entry)
            })
            .filter(|(score, _)| *score > 0.0)
            .collect();

        log::info!("âœ… æ‰¾åˆ° {} ä¸ªç›¸å…³æ¡ç›®", scored_entries.len());

        // æŒ‰åˆ†æ•°é™åºæ’åº
        scored_entries.sort_by(|a, b| b.0.partial_cmp(&a.0).unwrap_or(std::cmp::Ordering::Equal));

        // è¿”å›å‰ limit ä¸ªç»“æœ
        Ok(scored_entries
            .into_iter()
            .take(limit)
            .map(|(score, entry)| SearchResult {
                score,
                title: entry.title,
                content: entry.content,
                url: entry.url,
            })
            .collect())
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SearchResult {
    pub score: f32,
    pub title: String,
    pub content: String,
    pub url: String,
}

/// è®¡ç®—æ–‡æœ¬ç›¸å…³æ€§åˆ†æ•°ï¼ˆç®€åŒ–ç®—æ³•ï¼‰
/// è¿”å› 0.0-1.0 ä¹‹é—´çš„åˆ†æ•°
fn calculate_relevance_score(entry: &WikiEntry, query_lower: &str, query_words: &[&str]) -> f32 {
    let title_lower = entry.title.to_lowercase();
    let content_lower = entry.content.to_lowercase();

    let mut score = 0.0;
    let mut max_possible_score = 0.0;

    // 1. å®Œå…¨åŒ¹é…æŸ¥è¯¢å­—ç¬¦ä¸²ï¼ˆæœ€é«˜æƒé‡ï¼‰
    max_possible_score += 15.0;
    if title_lower.contains(query_lower) {
        score += 10.0;
    }
    if content_lower.contains(query_lower) {
        score += 5.0;
    }

    // 2. æ ‡é¢˜åŒ…å«æŸ¥è¯¢è¯ï¼ˆé«˜æƒé‡ï¼‰
    for word in query_words {
        max_possible_score += 3.0;
        if title_lower.contains(word) {
            score += 3.0;
        }
    }

    // 3. å†…å®¹åŒ…å«æŸ¥è¯¢è¯ï¼ˆä¸­æƒé‡ï¼‰
    // é™åˆ¶æœ€å¤šè®¡æ•° 10 æ¬¡,é¿å…åˆ†æ•°è¿‡é«˜
    for word in query_words {
        let count = content_lower.matches(word).count().min(10);
        max_possible_score += 5.0; // æ¯ä¸ªè¯æœ€å¤š 5 åˆ† (10æ¬¡ * 0.5)
        score += count as f32 * 0.5;
    }

    // å½’ä¸€åŒ–åˆ° 0.0-1.0
    if max_possible_score > 0.0 {
        let normalized_score = (score / max_possible_score).min(1.0);
        
        // 4. æ ‡é¢˜è¶ŠçŸ­ï¼Œç›¸å…³æ€§è¶Šé«˜ï¼ˆè½»å¾®åŠ åˆ†ï¼Œæœ€å¤š +10%ï¼‰
        if normalized_score > 0.0 {
            let title_len_penalty = (entry.title.len() as f32 / 100.0).min(1.0);
            let bonus = (1.0 - title_len_penalty) * 0.1;
            return (normalized_score + bonus).min(1.0);
        }
        normalized_score
    } else {
        0.0
    }
}
