// Continuous Listener - æŒç»­ç›‘å¬æ¨¡å¼çš„è¯­éŸ³è¾“å…¥ç³»ç»Ÿ
// é›†æˆ VAD + å½•éŸ³ + STT + AI å¤„ç†

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};
use std::time::Duration;
use tokio::sync::mpsc;
use tokio::task::JoinHandle;

use super::recorder::{AudioRecorder, RecorderConfig};
use super::vad::{VadConfig, VadState, VoiceActivityDetector};
use rubato::{Resampler, SincFixedIn, SincInterpolationType, SincInterpolationParameters, WindowFunction};

#[cfg(windows)]
use super::stt_windows::WindowsSttEngine;

/// ç›‘å¬å™¨çŠ¶æ€ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ListenerState {
    /// å½“å‰ VAD çŠ¶æ€
    pub vad_state: VadState,
    /// æ˜¯å¦æ­£åœ¨ç›‘å¬
    pub is_listening: bool,
    /// å½“å‰å½•éŸ³æ—¶é•¿(ç§’)
    pub recording_duration: f32,
    /// éŸ³é¢‘ç¼“å†²åŒºå¤§å°(é‡‡æ ·ç‚¹æ•°)
    pub buffer_size: usize,
    /// æœ€è¿‘ä¸€æ¬¡è¯†åˆ«çš„æ–‡å­—
    pub last_transcription: Option<String>,
}

/// æŒç»­ç›‘å¬å™¨äº‹ä»¶
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type", content = "data")]
pub enum ListenerEvent {
    /// å¼€å§‹è¯´è¯
    SpeechStarted,
    /// åœæ­¢è¯´è¯
    SpeechEnded { duration_secs: f32 },
    /// è¯­éŸ³è¯†åˆ«å®Œæˆ
    VoiceTranscribed { text: String },
    /// AI å“åº”å°±ç»ª
    AiResponseReady { response: String },
    /// è¯·æ±‚é˜¿é‡Œäº‘è¯†åˆ« (åŒ…å«PCMæ•°æ®)
    AliyunRecognizeRequest {
        pcm_data: Vec<u8>,
        sample_rate: u32,
        duration_secs: f32,
    },
    /// é”™è¯¯
    Error { message: String },
}

/// æŒç»­ç›‘å¬å™¨
pub struct ContinuousListener {
    /// VAD é…ç½®
    vad_config: VadConfig,
    /// å½•éŸ³å™¨é…ç½®
    recorder_config: RecorderConfig,
    
    /// å…±äº«çŠ¶æ€
    state: Arc<Mutex<ListenerStateInternal>>,
    
    /// ç›‘å¬ä»»åŠ¡å¥æŸ„
    listen_task: Option<JoinHandle<()>>,
    
    /// äº‹ä»¶å‘é€å™¨
    event_tx: Option<mpsc::UnboundedSender<ListenerEvent>>,
    
    /// å®é™…çš„è®¾å¤‡é‡‡æ ·ç‡ï¼ˆåœ¨ start_listening æ—¶è®¾ç½®ï¼‰
    actual_sample_rate: Option<u32>,
}

/// å†…éƒ¨çŠ¶æ€ (éœ€è¦çº¿ç¨‹å®‰å…¨)
struct ListenerStateInternal {
    vad: VoiceActivityDetector,
    is_listening: bool,
    last_transcription: Option<String>,
}

impl ContinuousListener {
    /// åˆ›å»ºæ–°çš„æŒç»­ç›‘å¬å™¨
    pub fn new(vad_config: VadConfig, recorder_config: RecorderConfig) -> Self {
        let vad = VoiceActivityDetector::new(vad_config.clone());
        
        let state = Arc::new(Mutex::new(ListenerStateInternal {
            vad,
            is_listening: false,
            last_transcription: None,
        }));

        Self {
            vad_config,
            recorder_config,
            state,
            listen_task: None,
            event_tx: None,
            actual_sample_rate: None,
        }
    }

    /// å¼€å§‹æŒç»­ç›‘å¬
    pub fn start_listening(
        &mut self,
        event_callback: impl Fn(ListenerEvent) + Send + 'static,
    ) -> Result<()> {
        if self.listen_task.is_some() {
            log::warn!("âš ï¸ ç›‘å¬å·²ç»åœ¨è¿è¡Œä¸­");
            return Ok(());
        }

        // åˆ›å»ºäº‹ä»¶é€šé“
        let (tx, mut rx) = mpsc::unbounded_channel();
        self.event_tx = Some(tx.clone());

        // å¯åŠ¨äº‹ä»¶å¤„ç†ä»»åŠ¡
        tokio::spawn(async move {
            while let Some(event) = rx.recv().await {
                event_callback(event);
            }
        });

        // æ ‡è®°ä¸ºç›‘å¬çŠ¶æ€
        {
            let mut state = self.state.lock().unwrap();
            state.is_listening = true;
            state.vad.reset();
        }

        // å¯åŠ¨ç›‘å¬å¾ªç¯
        let state = Arc::clone(&self.state);
        let recorder_config = self.recorder_config.clone();
        let event_tx = tx.clone();

        let handle = tokio::spawn(async move {
            if let Err(e) = Self::listen_loop(state, recorder_config, event_tx).await {
                log::error!("âŒ ç›‘å¬å¾ªç¯é”™è¯¯: {}", e);
            }
        });

        self.listen_task = Some(handle);
        log::info!("ğŸ™ï¸ å¼€å§‹æŒç»­ç›‘å¬");

        Ok(())
    }

    /// åœæ­¢æŒç»­ç›‘å¬
    pub fn stop_listening(&mut self) -> Result<()> {
        println!("â¹ï¸â¹ï¸â¹ï¸ stop_listening() è¢«è°ƒç”¨ !!!");
        log::info!("â¹ï¸ æ”¶åˆ°åœæ­¢ç›‘å¬è¯·æ±‚");
        
        // å…ˆæ£€æŸ¥ event_tx æ˜¯å¦å­˜åœ¨
        if self.event_tx.is_none() {
            println!("âš ï¸âš ï¸âš ï¸ event_tx ä¸º Noneï¼Œç›‘å¬å™¨å¯èƒ½æœªå¯åŠ¨æˆ–å·²åœæ­¢");
            log::warn!("âš ï¸ event_tx ä¸º Noneï¼Œç›‘å¬å™¨å¯èƒ½æœªå¯åŠ¨æˆ–å·²åœæ­¢");
            return Ok(());
        }
        
        println!("âœ… event_tx å­˜åœ¨ï¼Œç»§ç»­å¤„ç†...");
        
        // åœ¨åœæ­¢å‰,æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„éŸ³é¢‘æ•°æ®
        let event_tx = self.event_tx.clone();
        let should_trigger_recognition = {
            let mut state = self.state.lock().unwrap();
            let buffer_size = state.vad.buffer_size();
            let recording_duration = state.vad.recording_duration();
            
            println!("ğŸ“Š éŸ³é¢‘ç¼“å†²åŒº: {} æ ·æœ¬, æ—¶é•¿: {:.2}s", buffer_size, recording_duration);
            
            // å¦‚æœæœ‰éŸ³é¢‘æ•°æ®ä¸”æŒç»­æ—¶é—´è¶³å¤Ÿ
            if buffer_size > 0 && recording_duration >= 0.3 {
                println!("ğŸ¯ æ‰‹åŠ¨åœæ­¢æ—¶è§¦å‘è¯†åˆ«: buffer={} æ ·æœ¬, duration={:.1}s", buffer_size, recording_duration);
                log::info!("ğŸ¯ æ‰‹åŠ¨åœæ­¢æ—¶è§¦å‘è¯†åˆ«: buffer={} æ ·æœ¬, duration={:.1}s",
                          buffer_size, recording_duration);
                
                // è·å–éŸ³é¢‘buffer
                let audio_samples = state.vad.take_audio_buffer();
                let duration = recording_duration;
                
                // è®¡ç®—å®é™…é‡‡æ ·ç‡: æ ·æœ¬æ•° / æ—¶é•¿
                let actual_sample_rate = (audio_samples.len() as f32 / duration) as u32;
                
                println!("ğŸ”„ å¼€å§‹é‡é‡‡æ ·: {} æ ·æœ¬ ä» {}Hz åˆ° 16000Hz", audio_samples.len(), actual_sample_rate);
                log::info!("ğŸ”„ è®¡ç®—çš„å®é™…é‡‡æ ·ç‡: {} Hz (æ ·æœ¬æ•°: {}, æ—¶é•¿: {:.2}s)", 
                          actual_sample_rate, audio_samples.len(), duration);
                
                // é‡é‡‡æ ·åˆ°16kHz
                match Self::resample_to_16khz(&audio_samples, actual_sample_rate) {
                    Ok(pcm_data) => {
                        println!("âœ… é‡é‡‡æ ·æˆåŠŸ: {} å­—èŠ‚ PCM æ•°æ®", pcm_data.len());
                        Some((pcm_data, actual_sample_rate, duration))
                    },
                    Err(e) => {
                        println!("âŒ é‡é‡‡æ ·å¤±è´¥: {}", e);
                        log::error!("âŒ é‡é‡‡æ ·å¤±è´¥: {}", e);
                        None
                    }
                }
            } else {
                if buffer_size > 0 {
                    println!("âš ï¸ éŸ³é¢‘æ•°æ®è¿‡çŸ­,ä¸è§¦å‘è¯†åˆ«: duration={:.1}s", recording_duration);
                    log::warn!("âš ï¸ éŸ³é¢‘æ•°æ®è¿‡çŸ­,ä¸è§¦å‘è¯†åˆ«: duration={:.1}s", recording_duration);
                } else {
                    println!("âš ï¸ æ²¡æœ‰éŸ³é¢‘æ•°æ®");
                }
                None
            }
        };
        
        // åœ¨é‡Šæ”¾é”åå‘é€äº‹ä»¶
        if let Some((pcm_data, sample_rate, duration)) = should_trigger_recognition {
            if let Some(tx) = event_tx {
                println!("ğŸš€ğŸš€ğŸš€ å‡†å¤‡å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚ !!!");
                println!("   - PCM æ•°æ®å¤§å°: {} å­—èŠ‚", pcm_data.len());
                println!("   - é‡‡æ ·ç‡: {} Hz", sample_rate);
                println!("   - éŸ³é¢‘æ—¶é•¿: {:.2} ç§’", duration);
                
                log::info!("ğŸš€ å‡†å¤‡å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚:");
                log::info!("   - PCM æ•°æ®å¤§å°: {} å­—èŠ‚", pcm_data.len());
                log::info!("   - é‡‡æ ·ç‡: {} Hz", sample_rate);
                log::info!("   - éŸ³é¢‘æ—¶é•¿: {:.2} ç§’", duration);
                log::info!("   - è®¡ç®—çš„éŸ³é¢‘æ—¶é•¿: {:.2} ç§’", pcm_data.len() as f32 / (16000.0 * 2.0));
                
                if let Err(e) = tx.send(ListenerEvent::AliyunRecognizeRequest {
                    pcm_data,
                    sample_rate,
                    duration_secs: duration,
                }) {
                    println!("âŒ å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶å¤±è´¥: {}", e);
                    log::error!("âŒ å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶å¤±è´¥: {}", e);
                } else {
                    println!("ğŸ“¤ğŸ“¤ğŸ“¤ å·²å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶ !!!");
                    log::info!("ğŸ“¤ å·²å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶");
                    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©äº‹ä»¶å¾ªç¯å¤„ç†äº‹ä»¶
                    std::thread::sleep(std::time::Duration::from_millis(100));
                }
            } else {
                println!("âŒâŒâŒ event_tx ä¸º Noneï¼Œæ— æ³•å‘é€è¯†åˆ«è¯·æ±‚ !!!");
                log::error!("âŒ event_tx ä¸º Noneï¼Œæ— æ³•å‘é€è¯†åˆ«è¯·æ±‚");
            }
        } else {
            println!("âš ï¸ æ²¡æœ‰è§¦å‘è¯†åˆ«ï¼ˆéŸ³é¢‘å¯èƒ½è¿‡çŸ­æˆ–é‡é‡‡æ ·å¤±è´¥ï¼‰");
            log::warn!("âš ï¸ æ²¡æœ‰è§¦å‘è¯†åˆ«ï¼ˆéŸ³é¢‘å¯èƒ½è¿‡çŸ­æˆ–é‡é‡‡æ ·å¤±è´¥ï¼‰");
        }
        
        // æ ‡è®°ä¸ºåœæ­¢ç›‘å¬
        {
            let mut state = self.state.lock().unwrap();
            state.is_listening = false;
        }

        // ç­‰å¾…ä»»åŠ¡ç»“æŸ
        if let Some(handle) = self.listen_task.take() {
            handle.abort();
            log::info!("â¹ï¸ åœæ­¢æŒç»­ç›‘å¬");
        }

        self.event_tx = None;

        Ok(())
    }

    /// è·å–å½“å‰çŠ¶æ€
    pub fn get_state(&self) -> ListenerState {
        let state = self.state.lock().unwrap();
        ListenerState {
            vad_state: state.vad.state(),
            is_listening: state.is_listening,
            recording_duration: state.vad.recording_duration(),
            buffer_size: state.vad.buffer_size(),
            last_transcription: state.last_transcription.clone(),
        }
    }

    /// ç›‘å¬å¾ªç¯ (å¼‚æ­¥ä»»åŠ¡)
    async fn listen_loop(
        state: Arc<Mutex<ListenerStateInternal>>,
        recorder_config: RecorderConfig,
        event_tx: mpsc::UnboundedSender<ListenerEvent>,
    ) -> Result<()> {
        // åœ¨ spawn_blocking ä¸­è¿è¡Œ,å› ä¸º cpal Stream ä¸æ˜¯ Send
        tokio::task::spawn_blocking(move || {
            Self::listen_loop_blocking(state, recorder_config, event_tx)
        })
        .await
        .map_err(|e| anyhow::anyhow!("ç›‘å¬ä»»åŠ¡å¤±è´¥: {}", e))??;
        
        Ok(())
    }
    
    /// ç›‘å¬å¾ªç¯ (é˜»å¡ç‰ˆæœ¬,åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œ)
    fn listen_loop_blocking(
        state: Arc<Mutex<ListenerStateInternal>>,
        recorder_config: RecorderConfig,
        event_tx: mpsc::UnboundedSender<ListenerEvent>,
    ) -> Result<()> {
        // åˆ›å»ºå½•éŸ³å™¨
        let mut recorder = AudioRecorder::new(recorder_config.clone())
            .context("æ— æ³•åˆ›å»ºå½•éŸ³å™¨")?;
        
        // è·å–å®é™…çš„è®¾å¤‡é‡‡æ ·ç‡ï¼ˆå¯èƒ½ä¸é…ç½®ä¸åŒï¼‰
        let actual_sample_rate = recorder.actual_sample_rate();
        log::info!("ğŸ¤ å®é™…è®¾å¤‡é‡‡æ ·ç‡: {} Hz (é…ç½®: {} Hz)", 
                  actual_sample_rate, recorder_config.sample_rate);

        // å¼€å§‹å½•éŸ³
        recorder.start_recording()?;

        // éŸ³é¢‘å¤„ç†é—´éš” (æ¯«ç§’)
        let process_interval = Duration::from_millis(100);

        loop {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­ç›‘å¬
            {
                let state = state.lock().unwrap();
                if !state.is_listening {
                    break;
                }
            }

            // ç­‰å¾…ä¸€æ®µæ—¶é—´å†å¤„ç†
            std::thread::sleep(process_interval);

            // è·å–éŸ³é¢‘æ•°æ®
            let audio_chunk = recorder.take_audio_data();
            if audio_chunk.is_empty() {
                continue;
            }

            // VAD å¤„ç†
            let should_trigger_stt = {
                let mut state = state.lock().unwrap();
                let old_vad_state = state.vad.state();
                let should_trigger = state.vad.process_audio(&audio_chunk);

                // æ£€æµ‹çŠ¶æ€å˜åŒ–,å‘é€äº‹ä»¶
                let new_vad_state = state.vad.state();
                if old_vad_state != new_vad_state {
                    match new_vad_state {
                        VadState::Speaking => {
                            let _ = event_tx.send(ListenerEvent::SpeechStarted);
                        }
                        VadState::Processing => {
                            let duration = state.vad.recording_duration();
                            let _ = event_tx.send(ListenerEvent::SpeechEnded {
                                duration_secs: duration,
                            });
                        }
                        _ => {}
                    }
                }

                should_trigger
            };

            // å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ,ä¸å†è‡ªåŠ¨è§¦å‘STT
            // åŸå› : Windows STTæœ‰é‡‡æ ·ç‡é—®é¢˜,æ”¹ç”¨æ‰‹åŠ¨åœæ­¢è§¦å‘é˜¿é‡Œäº‘ASR
            if should_trigger_stt {
                // ä¸è¦å–å‡ºéŸ³é¢‘æ•°æ®,è®©å®ƒä¿ç•™åœ¨VADç¼“å†²åŒºä¸­
                // ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨åœæ­¢æ—¶å†å¤„ç†
                let buffer_size = {
                    let state = state.lock().unwrap();
                    state.vad.buffer_size()
                };

                log::info!("ğŸ¯ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ, éŸ³é¢‘: {} samples @ {} Hz (å·²ç¼“å­˜,ç­‰å¾…æ‰‹åŠ¨åœæ­¢)", 
                          buffer_size, actual_sample_rate);
                
                // ä¸æ‰§è¡Œè‡ªåŠ¨STT,ä¸å–å‡ºéŸ³é¢‘æ•°æ®,ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨åœæ­¢ä»¥è§¦å‘é˜¿é‡Œäº‘ASR
                // è¿™æ ·å¯ä»¥é¿å…Windows STTçš„é‡‡æ ·ç‡é—®é¢˜,å¹¶ä¸”ä¿ç•™éŸ³é¢‘æ•°æ®
            }

            // ç­‰å¾…ä¸‹ä¸€æ¬¡å¤„ç†
        }

        // åœæ­¢å½•éŸ³
        recorder.stop_recording()?;

        Ok(())
    }

    /// å¤„ç†è¯­éŸ³ç‰‡æ®µ:STT è¯†åˆ«
    #[cfg(windows)]
    async fn process_voice_segment(audio_data: &[f32], sample_rate: u32) -> Result<String> {
        let mut stt_engine = WindowsSttEngine::new()?;
        let text = stt_engine.recognize_from_audio(audio_data, sample_rate).await?;
        Ok(text)
    }

    /// é Windows å¹³å°çš„å ä½å®ç°
    #[cfg(not(windows))]
    async fn process_voice_segment(_audio_data: &[f32], _sample_rate: u32) -> Result<String> {
        anyhow::bail!("STT ä»…æ”¯æŒ Windows å¹³å°");
    }

    /// é‡é‡‡æ ·éŸ³é¢‘æ•°æ®åˆ°16kHz
    /// è¾“å…¥: f32æ ·æœ¬æ•°æ®, åŸå§‹é‡‡æ ·ç‡
    /// è¾“å‡º: 16kHz PCM u8æ•°æ® (16-bit little-endian)
    fn resample_to_16khz(samples: &[f32], from_rate: u32) -> Result<Vec<u8>> {
        const TARGET_RATE: u32 = 16000;
        
        if from_rate == TARGET_RATE {
            // ä¸éœ€è¦é‡é‡‡æ ·,ç›´æ¥è½¬æ¢ä¸ºPCM
            let pcm_data: Vec<u8> = samples
                .iter()
                .flat_map(|&s| {
                    let sample_i16 = (s.clamp(-1.0, 1.0) * 32767.0) as i16;
                    sample_i16.to_le_bytes()
                })
                .collect();
            return Ok(pcm_data);
        }
        
        log::info!("ğŸ”„ é‡é‡‡æ ·: {} Hz -> {} Hz ({} æ ·æœ¬)", from_rate, TARGET_RATE, samples.len());
        
        // åˆ›å»ºé‡é‡‡æ ·å™¨
        let params = SincInterpolationParameters {
            sinc_len: 256,
            f_cutoff: 0.95,
            interpolation: SincInterpolationType::Linear,
            oversampling_factor: 256,
            window: WindowFunction::BlackmanHarris2,
        };
        
        let mut resampler = SincFixedIn::<f32>::new(
            TARGET_RATE as f64 / from_rate as f64,
            2.0,
            params,
            samples.len(),
            1, // mono
        ).context("åˆ›å»ºé‡é‡‡æ ·å™¨å¤±è´¥")?;
        
        // é‡é‡‡æ · (éœ€è¦ Vec<Vec<f32>> æ ¼å¼)
        let input = vec![samples.to_vec()];
        let output = resampler.process(&input, None).context("é‡é‡‡æ ·å¤±è´¥")?;
        
        // è½¬æ¢ä¸ºPCM (16-bit little-endian)
        let resampled_samples = &output[0];
        let pcm_data: Vec<u8> = resampled_samples
            .iter()
            .flat_map(|&s| {
                let sample_i16 = (s.clamp(-1.0, 1.0) * 32767.0) as i16;
                sample_i16.to_le_bytes()
            })
            .collect();
        
        log::info!("âœ… é‡é‡‡æ ·å®Œæˆ: {} æ ·æœ¬ -> {} æ ·æœ¬ ({} å­—èŠ‚ PCM)",
                  samples.len(), resampled_samples.len(), pcm_data.len());
        
        Ok(pcm_data)
    }
}

impl Drop for ContinuousListener {
    fn drop(&mut self) {
        let _ = self.stop_listening();
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_listener_creation() {
        let vad_config = VadConfig::default();
        let recorder_config = RecorderConfig::default();
        let listener = ContinuousListener::new(vad_config, recorder_config);

        let state = listener.get_state();
        assert!(!state.is_listening);
        assert_eq!(state.vad_state, VadState::Idle);
    }
}
