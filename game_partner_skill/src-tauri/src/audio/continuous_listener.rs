// Continuous Listener - æŒç»­ç›‘å¬æ¨¡å¼çš„è¯­éŸ³è¾“å…¥ç³»ç»Ÿ
// é›†æˆ VAD + å½•éŸ³ + STT + AI å¤„ç†

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};
use std::time::Duration;
use tokio::sync::mpsc;
use tokio::task::JoinHandle;

use super::recorder::{AudioRecorder, RecorderConfig};
use super::vad::{VadConfig, VadState, VoiceActivityDetector};
use rubato::{
    Resampler, SincFixedIn, SincInterpolationParameters, SincInterpolationType, WindowFunction,
};

#[cfg(windows)]
use super::stt_windows::WindowsSttEngine;

/// ç›‘å¬å™¨çŠ¶æ€ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ListenerState {
    /// å½“å‰ VAD çŠ¶æ€
    pub vad_state: VadState,
    /// æ˜¯å¦æ­£åœ¨ç›‘å¬
    pub is_listening: bool,
    /// å½“å‰å½•éŸ³æ—¶é•¿(ç§’)
    pub recording_duration: f32,
    /// éŸ³é¢‘ç¼“å†²åŒºå¤§å°(é‡‡æ ·ç‚¹æ•°)
    pub buffer_size: usize,
    /// æœ€è¿‘ä¸€æ¬¡è¯†åˆ«çš„æ–‡å­—
    pub last_transcription: Option<String>,
}

/// æŒç»­ç›‘å¬å™¨äº‹ä»¶
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type", content = "data")]
pub enum ListenerEvent {
    /// å¼€å§‹è¯´è¯
    SpeechStarted,
    /// åœæ­¢è¯´è¯
    SpeechEnded { duration_secs: f32 },
    /// è¯­éŸ³è¯†åˆ«å®Œæˆ
    VoiceTranscribed { text: String },
    /// AI å“åº”å°±ç»ª
    AiResponseReady { response: String },
    /// è¯·æ±‚é˜¿é‡Œäº‘è¯†åˆ« (åŒ…å«PCMæ•°æ®)
    AliyunRecognizeRequest {
        pcm_data: Vec<u8>,
        sample_rate: u32,
        duration_secs: f32,
    },
    /// é”™è¯¯
    Error { message: String },
}

/// æŒç»­ç›‘å¬å™¨
pub struct ContinuousListener {
    /// VAD é…ç½®
    vad_config: VadConfig,
    /// å½•éŸ³å™¨é…ç½®
    recorder_config: RecorderConfig,

    /// å…±äº«çŠ¶æ€
    state: Arc<Mutex<ListenerStateInternal>>,

    /// ç›‘å¬ä»»åŠ¡å¥æŸ„
    listen_task: Option<JoinHandle<()>>,

    /// äº‹ä»¶å‘é€å™¨
    event_tx: Option<mpsc::UnboundedSender<ListenerEvent>>,

    /// å®é™…çš„è®¾å¤‡é‡‡æ ·ç‡ï¼ˆåœ¨ start_listening æ—¶è®¾ç½®ï¼‰
    actual_sample_rate: Option<u32>,
}

/// å†…éƒ¨çŠ¶æ€ (éœ€è¦çº¿ç¨‹å®‰å…¨)
struct ListenerStateInternal {
    vad: VoiceActivityDetector,
    is_listening: bool,
    last_transcription: Option<String>,
}

impl ContinuousListener {
    /// åˆ›å»ºæ–°çš„æŒç»­ç›‘å¬å™¨
    pub fn new(vad_config: VadConfig, recorder_config: RecorderConfig) -> Self {
        let vad = VoiceActivityDetector::new(vad_config.clone());

        let state = Arc::new(Mutex::new(ListenerStateInternal {
            vad,
            is_listening: false,
            last_transcription: None,
        }));

        Self {
            vad_config,
            recorder_config,
            state,
            listen_task: None,
            event_tx: None,
            actual_sample_rate: None,
        }
    }

    /// å¼€å§‹æŒç»­ç›‘å¬
    pub fn start_listening(
        &mut self,
        event_callback: impl Fn(ListenerEvent) + Send + 'static,
    ) -> Result<()> {
        if self.listen_task.is_some() {
            log::warn!("ç›‘å¬å·²ç»åœ¨è¿è¡Œä¸­");
            return Ok(());
        }

        // åˆ›å»ºäº‹ä»¶é€šé“
        let (tx, mut rx) = mpsc::unbounded_channel();
        self.event_tx = Some(tx.clone());

        // å¯åŠ¨äº‹ä»¶å¤„ç†ä»»åŠ¡
        tokio::spawn(async move {
            while let Some(event) = rx.recv().await {
                event_callback(event);
            }
        });

        // æ ‡è®°ä¸ºç›‘å¬çŠ¶æ€
        {
            let mut state = self.state.lock().unwrap();
            state.is_listening = true;
            state.vad.reset();
        }

        // å¯åŠ¨ç›‘å¬å¾ªç¯
        let state = Arc::clone(&self.state);
        let recorder_config = self.recorder_config.clone();
        let event_tx = tx.clone();

        let handle = tokio::spawn(async move {
            if let Err(e) = Self::listen_loop(state, recorder_config, event_tx).await {
                log::error!("ç›‘å¬å¾ªç¯é”™è¯¯: {}", e);
            }
        });

        self.listen_task = Some(handle);

        Ok(())
    }

    /// åœæ­¢æŒç»­ç›‘å¬
    pub fn stop_listening(&mut self) -> Result<()> {
        // å…ˆæ£€æŸ¥ event_tx æ˜¯å¦å­˜åœ¨
        if self.event_tx.is_none() {
            log::warn!("âš ï¸ event_tx ä¸º Noneï¼Œç›‘å¬å™¨å¯èƒ½æœªå¯åŠ¨æˆ–å·²åœæ­¢");
            return Ok(());
        }

        // åœ¨åœæ­¢å‰,æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„éŸ³é¢‘æ•°æ®
        let event_tx = self.event_tx.clone();
        let should_trigger_recognition = {
            let mut state = self.state.lock().unwrap();
            let buffer_size = state.vad.buffer_size();
            let recording_duration = state.vad.recording_duration();
            // å¦‚æœæœ‰éŸ³é¢‘æ•°æ®ä¸”æŒç»­æ—¶é—´è¶³å¤Ÿ
            if buffer_size > 0 && recording_duration >= 0.3 {
                // è·å–éŸ³é¢‘buffer
                let audio_samples = state.vad.take_audio_buffer();
                let duration = recording_duration;

                // è®¡ç®—å®é™…é‡‡æ ·ç‡: æ ·æœ¬æ•° / æ—¶é•¿
                let actual_sample_rate = (audio_samples.len() as f32 / duration) as u32;

                // é‡é‡‡æ ·åˆ°16kHz
                match Self::resample_to_16khz(&audio_samples, actual_sample_rate) {
                    Ok(pcm_data) => {
                        // // ä¿å­˜ WAV æ–‡ä»¶åˆ°ä¸‹è½½ç›®å½•
                        // if let Err(e) = Self::save_wav_file(&pcm_data, 16000, duration) {
                        //     log::error!("âŒ ä¿å­˜ WAV æ–‡ä»¶å¤±è´¥: {}", e);
                        // }
                        Some((pcm_data, actual_sample_rate, duration))
                    }
                    Err(e) => {
                        log::error!("âŒ é‡é‡‡æ ·å¤±è´¥: {}", e);
                        None
                    }
                }
            } else {
                if buffer_size > 0 {
                    log::warn!(
                        "âš ï¸ éŸ³é¢‘æ•°æ®è¿‡çŸ­,ä¸è§¦å‘è¯†åˆ«: duration={:.1}s",
                        recording_duration
                    );
                } else {
                    println!("âš ï¸ æ²¡æœ‰éŸ³é¢‘æ•°æ®");
                }
                None
            }
        };

        // åœ¨é‡Šæ”¾é”åå‘é€äº‹ä»¶
        if let Some((pcm_data, sample_rate, duration)) = should_trigger_recognition {
            if let Some(tx) = event_tx {
                println!("ğŸš€ğŸš€ğŸš€ å‡†å¤‡å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚ !!!");
                println!("   - PCM æ•°æ®å¤§å°: {} å­—èŠ‚", pcm_data.len());
                println!("   - é‡‡æ ·ç‡: {} Hz", sample_rate);
                println!("   - éŸ³é¢‘æ—¶é•¿: {:.2} ç§’", duration);

                log::info!("ğŸš€ å‡†å¤‡å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚:");
                log::info!("   - PCM æ•°æ®å¤§å°: {} å­—èŠ‚", pcm_data.len());
                log::info!("   - é‡‡æ ·ç‡: {} Hz", sample_rate);
                log::info!("   - éŸ³é¢‘æ—¶é•¿: {:.2} ç§’", duration);
                log::info!(
                    "   - è®¡ç®—çš„éŸ³é¢‘æ—¶é•¿: {:.2} ç§’",
                    pcm_data.len() as f32 / (16000.0 * 2.0)
                );

                if let Err(e) = tx.send(ListenerEvent::AliyunRecognizeRequest {
                    pcm_data,
                    sample_rate,
                    duration_secs: duration,
                }) {
                    println!("âŒ å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶å¤±è´¥: {}", e);
                    log::error!("âŒ å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶å¤±è´¥: {}", e);
                } else {
                    println!("ğŸ“¤ğŸ“¤ğŸ“¤ å·²å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶ !!!");
                    log::info!("ğŸ“¤ å·²å‘é€é˜¿é‡Œäº‘è¯†åˆ«è¯·æ±‚äº‹ä»¶");
                    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©äº‹ä»¶å¾ªç¯å¤„ç†äº‹ä»¶
                    std::thread::sleep(std::time::Duration::from_millis(100));
                }
            } else {
                println!("âŒâŒâŒ event_tx ä¸º Noneï¼Œæ— æ³•å‘é€è¯†åˆ«è¯·æ±‚ !!!");
                log::error!("âŒ event_tx ä¸º Noneï¼Œæ— æ³•å‘é€è¯†åˆ«è¯·æ±‚");
            }
        } else {
            println!("âš ï¸ æ²¡æœ‰è§¦å‘è¯†åˆ«ï¼ˆéŸ³é¢‘å¯èƒ½è¿‡çŸ­æˆ–é‡é‡‡æ ·å¤±è´¥ï¼‰");
            log::warn!("âš ï¸ æ²¡æœ‰è§¦å‘è¯†åˆ«ï¼ˆéŸ³é¢‘å¯èƒ½è¿‡çŸ­æˆ–é‡é‡‡æ ·å¤±è´¥ï¼‰");
        }

        // æ ‡è®°ä¸ºåœæ­¢ç›‘å¬
        {
            let mut state = self.state.lock().unwrap();
            state.is_listening = false;
        }

        // ç­‰å¾…ä»»åŠ¡ç»“æŸ
        if let Some(handle) = self.listen_task.take() {
            handle.abort();
            log::info!("â¹ï¸ åœæ­¢æŒç»­ç›‘å¬");
        }

        self.event_tx = None;

        Ok(())
    }

    /// è·å–å½“å‰çŠ¶æ€
    pub fn get_state(&self) -> ListenerState {
        let state = self.state.lock().unwrap();
        ListenerState {
            vad_state: state.vad.state(),
            is_listening: state.is_listening,
            recording_duration: state.vad.recording_duration(),
            buffer_size: state.vad.buffer_size(),
            last_transcription: state.last_transcription.clone(),
        }
    }

    /// ç›‘å¬å¾ªç¯ (å¼‚æ­¥ä»»åŠ¡)
    async fn listen_loop(
        state: Arc<Mutex<ListenerStateInternal>>,
        recorder_config: RecorderConfig,
        event_tx: mpsc::UnboundedSender<ListenerEvent>,
    ) -> Result<()> {
        // åœ¨ spawn_blocking ä¸­è¿è¡Œ,å› ä¸º cpal Stream ä¸æ˜¯ Send
        tokio::task::spawn_blocking(move || {
            Self::listen_loop_blocking(state, recorder_config, event_tx)
        })
        .await
        .map_err(|e| anyhow::anyhow!("ç›‘å¬ä»»åŠ¡å¤±è´¥: {}", e))??;

        Ok(())
    }

    /// ç›‘å¬å¾ªç¯ (é˜»å¡ç‰ˆæœ¬,åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œ)
    fn listen_loop_blocking(
        state: Arc<Mutex<ListenerStateInternal>>,
        recorder_config: RecorderConfig,
        event_tx: mpsc::UnboundedSender<ListenerEvent>,
    ) -> Result<()> {
        // åˆ›å»ºå½•éŸ³å™¨
        let mut recorder = AudioRecorder::new(recorder_config.clone()).context("æ— æ³•åˆ›å»ºå½•éŸ³å™¨")?;

        // è·å–å®é™…çš„è®¾å¤‡é‡‡æ ·ç‡ï¼ˆå¯èƒ½ä¸é…ç½®ä¸åŒï¼‰
        let actual_sample_rate = recorder.actual_sample_rate();
        log::info!(
            "ğŸ¤ å®é™…è®¾å¤‡é‡‡æ ·ç‡: {} Hz (é…ç½®: {} Hz)",
            actual_sample_rate,
            recorder_config.sample_rate
        );

        // å¼€å§‹å½•éŸ³
        recorder.start_recording()?;

        // éŸ³é¢‘å¤„ç†é—´éš” (æ¯«ç§’)
        let process_interval = Duration::from_millis(100);

        loop {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­ç›‘å¬
            {
                let state = state.lock().unwrap();
                if !state.is_listening {
                    break;
                }
            }

            // ç­‰å¾…ä¸€æ®µæ—¶é—´å†å¤„ç†
            std::thread::sleep(process_interval);

            // è·å–éŸ³é¢‘æ•°æ®
            let audio_chunk = recorder.take_audio_data();

            // æ£€æŸ¥éŸ³é¢‘æ•°æ®
            if audio_chunk.is_empty() {
                continue;
            }

            // VAD å¤„ç†
            let (should_trigger_stt, speech_ended_with_audio) = {
                let mut state = state.lock().unwrap();
                let old_vad_state = state.vad.state();

                let should_trigger = state.vad.process_audio(&audio_chunk);

                // æ£€æµ‹çŠ¶æ€å˜åŒ–,å‘é€äº‹ä»¶
                let new_vad_state = state.vad.state();

                // å¦‚æœä» Speaking åˆ‡æ¢åˆ° Processingï¼Œç«‹å³å–å‡ºéŸ³é¢‘æ•°æ®
                let audio_data_for_recognition = if old_vad_state == VadState::Speaking
                    && new_vad_state == VadState::Processing
                {
                    let buffer = state.vad.take_audio_buffer();
                    let duration = state.vad.recording_duration();

                    if buffer.len() > 0 && duration >= 0.3 {
                        println!(
                            "ğŸ¤ æ£€æµ‹åˆ°åœæ­¢è¯´è¯ (æ—¶é•¿: {:.2}s, {} æ ·æœ¬)",
                            duration,
                            buffer.len()
                        );
                        log::info!(
                            "ğŸ¤ æ£€æµ‹åˆ°åœæ­¢è¯´è¯ (æ—¶é•¿: {:.2}s, {} æ ·æœ¬)",
                            duration,
                            buffer.len()
                        );
                        Some((buffer, duration))
                    } else {
                        println!("âš ï¸ è¯­éŸ³è¿‡çŸ­æˆ–æ— æ•°æ®ï¼Œå¿½ç•¥");
                        None
                    }
                } else {
                    None
                };

                // ğŸ” åªåœ¨çŠ¶æ€çœŸæ­£å˜åŒ–æ—¶æ‰“å°
                if old_vad_state != new_vad_state {
                    match new_vad_state {
                        VadState::Speaking => {
                            println!("ğŸ¤ æ£€æµ‹åˆ°å¼€å§‹è¯´è¯");
                            log::info!("ğŸ¤ æ£€æµ‹åˆ°å¼€å§‹è¯´è¯");
                            let _ = event_tx.send(ListenerEvent::SpeechStarted);
                        }
                        VadState::Processing => {
                            let duration = state.vad.recording_duration();
                            let _ = event_tx.send(ListenerEvent::SpeechEnded {
                                duration_secs: duration,
                            });
                        }
                        VadState::Idle => {
                            println!("ğŸ”„ VAD çŠ¶æ€æ¢å¤ç©ºé—²");
                            log::info!("ğŸ”„ VAD çŠ¶æ€æ¢å¤ç©ºé—²");
                        }
                    }
                }

                (should_trigger, audio_data_for_recognition)
            };

            // åœ¨é‡Šæ”¾é”åå¤„ç†éŸ³é¢‘è¯†åˆ«ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if let Some((audio_samples, duration)) = speech_ended_with_audio {
                // è®¡ç®—å®é™…é‡‡æ ·ç‡
                let actual_sample_rate = (audio_samples.len() as f32 / duration) as u32;

                println!(
                    "ğŸ”„ å¼€å§‹é‡é‡‡æ ·: {} æ ·æœ¬ ä» {}Hz åˆ° 16000Hz",
                    audio_samples.len(),
                    actual_sample_rate
                );
                log::info!(
                    "ğŸ”„ è®¡ç®—çš„å®é™…é‡‡æ ·ç‡: {} Hz (æ ·æœ¬æ•°: {}, æ—¶é•¿: {:.2}s)",
                    actual_sample_rate,
                    audio_samples.len(),
                    duration
                );

                // é‡é‡‡æ ·åˆ°16kHz
                match Self::resample_to_16khz(&audio_samples, actual_sample_rate) {
                    Ok(pcm_data) => {
                        // // ä¿å­˜ WAV æ–‡ä»¶åˆ°ä¸‹è½½ç›®å½•
                        // if let Err(e) = Self::save_wav_file(&pcm_data, 16000, duration) {
                        //     log::error!("ä¿å­˜ WAV æ–‡ä»¶å¤±è´¥: {}", e);
                        // }

                        // å‘é€è¯†åˆ«è¯·æ±‚
                        if let Err(e) = event_tx.send(ListenerEvent::AliyunRecognizeRequest {
                            pcm_data,
                            sample_rate: actual_sample_rate,
                            duration_secs: duration,
                        }) {
                            log::error!("å‘é€è¯†åˆ«è¯·æ±‚å¤±è´¥: {}", e);
                        }
                    }
                    Err(e) => {
                        log::error!("é‡é‡‡æ ·å¤±è´¥: {}", e);
                    }
                }
            }
        }

        // åœæ­¢å½•éŸ³
        recorder.stop_recording()?;

        Ok(())
    }

    /// å¤„ç†è¯­éŸ³ç‰‡æ®µ:STT è¯†åˆ«
    #[cfg(windows)]
    async fn process_voice_segment(audio_data: &[f32], sample_rate: u32) -> Result<String> {
        let mut stt_engine = WindowsSttEngine::new()?;
        let text = stt_engine
            .recognize_from_audio(audio_data, sample_rate)
            .await?;
        Ok(text)
    }

    /// é Windows å¹³å°çš„å ä½å®ç°
    #[cfg(not(windows))]
    async fn process_voice_segment(_audio_data: &[f32], _sample_rate: u32) -> Result<String> {
        anyhow::bail!("STT ä»…æ”¯æŒ Windows å¹³å°");
    }

    /// é‡é‡‡æ ·éŸ³é¢‘æ•°æ®åˆ°16kHz
    /// è¾“å…¥: f32æ ·æœ¬æ•°æ®, åŸå§‹é‡‡æ ·ç‡
    /// è¾“å‡º: 16kHz PCM u8æ•°æ® (16-bit little-endian)
    fn resample_to_16khz(samples: &[f32], from_rate: u32) -> Result<Vec<u8>> {
        const TARGET_RATE: u32 = 16000;

        if from_rate == TARGET_RATE {
            // ä¸éœ€è¦é‡é‡‡æ ·,ç›´æ¥è½¬æ¢ä¸ºPCM
            let pcm_data: Vec<u8> = samples
                .iter()
                .flat_map(|&s| {
                    let sample_i16 = (s.clamp(-1.0, 1.0) * 32767.0) as i16;
                    sample_i16.to_le_bytes()
                })
                .collect();
            return Ok(pcm_data);
        }
        // åˆ›å»ºé‡é‡‡æ ·å™¨
        let params = SincInterpolationParameters {
            sinc_len: 256,
            f_cutoff: 0.95,
            interpolation: SincInterpolationType::Linear,
            oversampling_factor: 256,
            window: WindowFunction::BlackmanHarris2,
        };

        let mut resampler = SincFixedIn::<f32>::new(
            TARGET_RATE as f64 / from_rate as f64,
            2.0,
            params,
            samples.len(),
            1, // mono
        )
        .context("åˆ›å»ºé‡é‡‡æ ·å™¨å¤±è´¥")?;

        // é‡é‡‡æ · (éœ€è¦ Vec<Vec<f32>> æ ¼å¼)
        let input = vec![samples.to_vec()];
        let output = resampler.process(&input, None).context("é‡é‡‡æ ·å¤±è´¥")?;

        // è½¬æ¢ä¸ºPCM (16-bit little-endian)
        let resampled_samples = &output[0];
        let pcm_data: Vec<u8> = resampled_samples
            .iter()
            .flat_map(|&s| {
                let sample_i16 = (s.clamp(-1.0, 1.0) * 32767.0) as i16;
                sample_i16.to_le_bytes()
            })
            .collect();

        Ok(pcm_data)
    }

    /// ä¿å­˜ WAV æ–‡ä»¶åˆ°ä¸‹è½½ç›®å½•
    fn save_wav_file(pcm_data: &[u8], sample_rate: u32, duration: f32) -> Result<()> {
        use std::fs::File;
        use std::io::Write;

        // ç”Ÿæˆæ–‡ä»¶åï¼ˆæ—¶é—´æˆ³ï¼‰
        let timestamp = chrono::Local::now().format("%Y%m%d_%H%M%S");
        let filename = format!("voice_{}_{:.1}s.wav", timestamp, duration);
        let filepath = format!(r"C:\Users\Administrator\Downloads\{}", filename);

        // åˆ›å»º WAV æ–‡ä»¶
        let mut file =
            File::create(&filepath).context(format!("åˆ›å»º WAV æ–‡ä»¶å¤±è´¥: {}", filepath))?;

        // å†™å…¥ WAV å¤´
        let num_samples = pcm_data.len() / 2; // 16-bit = 2 bytes per sample
        let byte_rate = sample_rate * 2; // 16-bit mono
        let data_size = pcm_data.len() as u32;
        let file_size = 36 + data_size;

        // RIFF header
        file.write_all(b"RIFF")?;
        file.write_all(&file_size.to_le_bytes())?;
        file.write_all(b"WAVE")?;

        // fmt chunk
        file.write_all(b"fmt ")?;
        file.write_all(&16u32.to_le_bytes())?; // chunk size
        file.write_all(&1u16.to_le_bytes())?; // audio format (1 = PCM)
        file.write_all(&1u16.to_le_bytes())?; // num channels (1 = mono)
        file.write_all(&sample_rate.to_le_bytes())?;
        file.write_all(&byte_rate.to_le_bytes())?;
        file.write_all(&2u16.to_le_bytes())?; // block align (2 = 16-bit mono)
        file.write_all(&16u16.to_le_bytes())?; // bits per sample

        // data chunk
        file.write_all(b"data")?;
        file.write_all(&data_size.to_le_bytes())?;
        file.write_all(pcm_data)?;

        log::info!(
            "å·²ä¿å­˜è¯­éŸ³æ–‡ä»¶: {} ({:.1}s, {} bytes)",
            filepath,
            duration,
            pcm_data.len()
        );

        Ok(())
    }
}

impl Drop for ContinuousListener {
    fn drop(&mut self) {
        let _ = self.stop_listening();
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_listener_creation() {
        let vad_config = VadConfig::default();
        let recorder_config = RecorderConfig::default();
        let listener = ContinuousListener::new(vad_config, recorder_config);

        let state = listener.get_state();
        assert!(!state.is_listening);
        assert_eq!(state.vad_state, VadState::Idle);
    }
}
