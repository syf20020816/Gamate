use crate::llm::OpenAIClient;
use crate::settings::ModelConfig;
use anyhow::Result;
use base64::{engine::general_purpose, Engine as _};
/// AI åˆ†ææœåŠ¡
///
/// æ¥æ”¶ä¸»æ’­è¯­éŸ³ + åŒæˆªå›¾ + å‘˜å·¥å¯¹è¯å†å²ï¼Œè¿”å›æ™ºèƒ½åŒ–çš„å¼¹å¹•å›å¤
use serde::{Deserialize, Serialize};
use std::sync::Arc;

/// AI åˆ†æè¯·æ±‚
#[derive(Debug, Clone, Serialize)]
pub struct AIAnalysisRequest {
    /// ä¸»æ’­è¯´çš„è¯ï¼ˆè¯­éŸ³è¯†åˆ«ç»“æœï¼‰
    pub streamer_speech: String,

    /// å¼€å§‹è¯´è¯æ—¶çš„æˆªå›¾ï¼ˆBase64ï¼‰
    pub screenshot_before: String,

    /// ç»“æŸè¯´è¯æ—¶çš„æˆªå›¾ï¼ˆBase64ï¼‰
    pub screenshot_after: String,

    /// å‘˜å·¥åˆ—è¡¨åŠå…¶å¯¹è¯å†å²
    pub employees: Vec<EmployeeContext>,
}

/// å‘˜å·¥ä¸Šä¸‹æ–‡ä¿¡æ¯
#[derive(Debug, Clone, Serialize)]
pub struct EmployeeContext {
    /// å‘˜å·¥ ID
    pub id: String,

    /// å‘˜å·¥æ˜µç§°
    pub nickname: String,

    /// å‘˜å·¥æ€§æ ¼
    pub personality: String,

    /// å¯¹è¯å†å²ï¼ˆæœ€è¿‘ 10 æ¡ï¼‰
    pub conversation_history: Vec<ConversationMessage>,
}

/// å¯¹è¯æ¶ˆæ¯
#[derive(Debug, Clone, Serialize)]
pub struct ConversationMessage {
    pub role: String, // "user" (ä¸»æ’­) æˆ– "assistant" (å‘˜å·¥)
    pub content: String,
}

/// AI åˆ†æå“åº”
#[derive(Debug, Clone, Deserialize)]
pub struct AIAnalysisResponse {
    pub actions: Vec<EmployeeAction>,
}

/// å‘˜å·¥è¡Œä¸ºå†³ç­–
#[derive(Debug, Clone, Deserialize)]
pub struct EmployeeAction {
    /// å‘˜å·¥ ID
    pub employee: String,

    /// è¦å‘é€çš„å¼¹å¹•å†…å®¹
    pub content: String,

    /// æ˜¯å¦å‘é€ç¤¼ç‰©
    pub gift: bool,

    /// ç¤¼ç‰©åç§°ï¼ˆå¦‚æœ gift = trueï¼‰
    #[serde(default)]
    pub gift_name: Option<String>,

    /// ç¤¼ç‰©æ•°é‡ï¼ˆå¦‚æœ gift = trueï¼‰
    #[serde(default)]
    pub gift_count: Option<u32>,
}

/// AI åˆ†æå™¨
#[derive(Clone)]
pub struct AIAnalyzer {
    client: Arc<OpenAIClient>,
    model: String,
}

impl AIAnalyzer {
    pub fn new(api_endpoint: String, api_key: String, model: String) -> Self {
        // æ„å»º ModelConfig
        let config = ModelConfig {
            provider: "openai".to_string(),
            api_base: api_endpoint,
            api_key: Some(api_key),
            model_name: model.clone(),
            enabled: true,
            temperature: 0.8,
            max_tokens: 2000,
        };

        let client = OpenAIClient::new(config).expect("åˆ›å»º OpenAI å®¢æˆ·ç«¯å¤±è´¥");

        Self {
            client: Arc::new(client),
            model,
        }
    }

    /// åˆ†æä¸»æ’­è¯­éŸ³å’Œæ¸¸æˆçŠ¶æ€ï¼Œç”Ÿæˆå‘˜å·¥äº’åŠ¨å†³ç­–
    pub async fn analyze(&self, request: AIAnalysisRequest) -> Result<AIAnalysisResponse, String> {
        // æ¸…ç†å’ŒéªŒè¯ base64 å›¾ç‰‡ï¼Œè¿‡æ»¤æ‰ç©ºæˆªå›¾
        let mut images = Vec::new();

        // å¤„ç†ç¬¬ä¸€å¼ æˆªå›¾
        if !request.screenshot_before.is_empty() {
            if let Ok(clean_img) = Self::sanitize_base64_image(&request.screenshot_before) {
                images.push(clean_img);
            }
        }

        // å¤„ç†ç¬¬äºŒå¼ æˆªå›¾
        if !request.screenshot_after.is_empty() {
            if let Ok(clean_img) = Self::sanitize_base64_image(&request.screenshot_after) {
                images.push(clean_img);
            }
        }

        // æ„å»ºæç¤ºè¯
        let user_prompt = self.build_prompt(&request, images.len());
        let system_prompt = "ä½ æ˜¯ä¸€ä¸ªç›´æ’­é—´äº’åŠ¨åˆ†æä¸“å®¶ã€‚æ ¹æ®ä¸»æ’­çš„è¯­éŸ³å’Œæ¸¸æˆç”»é¢å˜åŒ–ï¼Œä¸ºæ¯ä¸ªAIå‘˜å·¥ç”Ÿæˆè‡ªç„¶ã€æœ‰è¶£ã€ç¬¦åˆå…¶æ€§æ ¼çš„å¼¹å¹•å›å¤ã€‚\n\nä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š\n{\n  \"actions\": [\n    {\n      \"employee\": \"å‘˜å·¥ID\",\n      \"content\": \"å¼¹å¹•å†…å®¹\",\n      \"gift\": false\n    }\n  ]\n}";

        // è°ƒç”¨ OpenAI Multi-Vision API
        let ai_response = self
            .client
            .chat_with_multi_vision(system_prompt, &user_prompt, &images)
            .await
            .map_err(|e| format!("AI API è°ƒç”¨å¤±è´¥: {}", e))?;

        // è§£æ JSON å“åº”
        let response: AIAnalysisResponse = serde_json::from_str(&ai_response)
            .map_err(|e| format!("è§£æ AI å“åº” JSON å¤±è´¥: {}\nåŸå§‹å“åº”: {}", e, ai_response))?;

        Ok(response)
    }

    /// å‡€åŒ– base64 å›¾ç‰‡å­—ç¬¦ä¸²
    ///
    /// åŠŸèƒ½:
    /// 1. å»é™¤ data:image/...;base64, å‰ç¼€ (å¦‚æœæœ‰)
    /// 2. ç§»é™¤æ¢è¡Œç¬¦å’Œç©ºç™½å­—ç¬¦
    /// 3. æ ¡éªŒ base64 æ ¼å¼æ˜¯å¦æœ‰æ•ˆ
    /// 4. ç¡®ä¿è§£ç åçš„æ•°æ®ä¸ä¸ºç©º
    fn sanitize_base64_image(s: &str) -> Result<String, String> {
        let mut cleaned = s.trim().to_string();

        // 0. æ£€æŸ¥åŸå§‹å­—ç¬¦ä¸²æ˜¯å¦ä¸ºç©º
        if cleaned.is_empty() {
            return Err("base64 å­—ç¬¦ä¸²ä¸ºç©º".to_string());
        }

        // 1. å»é™¤ data URL å‰ç¼€
        if let Some(comma_idx) = cleaned.find(',') {
            let prefix = &cleaned[..comma_idx];
            if prefix.starts_with("data:") && prefix.contains("base64") {
                cleaned = cleaned[comma_idx + 1..].to_string();
            }
        }

        // 2. ç§»é™¤æ‰€æœ‰æ¢è¡Œç¬¦å’Œç©ºç™½å­—ç¬¦
        cleaned.retain(|c| !c.is_whitespace());

        // 3. æ ¡éªŒ base64 æ ¼å¼
        match general_purpose::STANDARD.decode(&cleaned) {
            Ok(decoded) => {
                // 4. æ£€æŸ¥è§£ç åçš„æ•°æ®æ˜¯å¦ä¸ºç©º
                if decoded.is_empty() {
                    return Err("base64 è§£ç åæ•°æ®ä¸ºç©º".to_string());
                }
                Ok(cleaned)
            }
            Err(e) => {
                Err(format!("æ— æ•ˆçš„ base64 å›¾ç‰‡æ ¼å¼: {}", e))
            }
        }
    }

    /// æ„å»ºæç¤ºè¯
    fn build_prompt(&self, request: &AIAnalysisRequest, screenshot_count: usize) -> String {
        let screenshot_info = match screenshot_count {
            0 => "ï¼ˆæ²¡æœ‰æ¸¸æˆæˆªå›¾ï¼Œä»…æ ¹æ®è¯­éŸ³å†…å®¹åˆ†æï¼‰",
            1 => "- å›¾ç‰‡ï¼šä¸»æ’­è¯´è¯æ—¶çš„æ¸¸æˆçŠ¶æ€\nè¯·åˆ†ææ¸¸æˆç”»é¢ä¸­çš„å†…å®¹",
            2 => "- å›¾ç‰‡1ï¼šä¸»æ’­å¼€å§‹è¯´è¯æ—¶çš„æ¸¸æˆçŠ¶æ€\n- å›¾ç‰‡2ï¼šä¸»æ’­ç»“æŸè¯´è¯æ—¶çš„æ¸¸æˆçŠ¶æ€\nè¯·åˆ†ææ¸¸æˆç”»é¢ä¸­å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–ï¼ˆå¦‚è§’è‰²ç§»åŠ¨ã€æˆ˜æ–—ã€å¾—åˆ†ç­‰ï¼‰",
            _ => "- å¤šå¼ æ¸¸æˆæˆªå›¾\nè¯·åˆ†ææ¸¸æˆç”»é¢å˜åŒ–",
        };

        let mut prompt = format!(
            "# ç›´æ’­é—´äº’åŠ¨åˆ†æä»»åŠ¡\n\n\
            ## ä¸»æ’­è¯­éŸ³è¯†åˆ«ç»“æœ\n\
            \"{}\"\n\n\
            ## æ¸¸æˆç”»é¢å˜åŒ–\n\
            {}\n\n\
            ## AI å‘˜å·¥ä¿¡æ¯\n",
            request.streamer_speech, screenshot_info
        );

        // æ·»åŠ æ¯ä¸ªå‘˜å·¥çš„ä¿¡æ¯
        for (i, employee) in request.employees.iter().enumerate() {
            prompt.push_str(&format!(
                "### å‘˜å·¥ {} - {} (æ€§æ ¼: {})\n",
                i + 1,
                employee.nickname,
                self.get_personality_description(&employee.personality)
            ));

            // æ·»åŠ å¯¹è¯å†å²
            if !employee.conversation_history.is_empty() {
                prompt.push_str("**æœ€è¿‘å¯¹è¯å†å²:**\n");
                for msg in employee.conversation_history.iter().rev().take(5).rev() {
                    let role_label = if msg.role == "user" {
                        "ä¸»æ’­"
                    } else {
                        &employee.nickname
                    };
                    prompt.push_str(&format!("- {}: {}\n", role_label, msg.content));
                }
            } else {
                prompt.push_str("*ï¼ˆæš‚æ— å¯¹è¯å†å²ï¼‰*\n");
            }
            prompt.push('\n');
        }

        // æ·»åŠ ä»»åŠ¡è¦æ±‚
        prompt.push_str(
            "## ä»»åŠ¡è¦æ±‚\n\
            1. **åˆ†æä¸»æ’­çš„è¯å’Œæ¸¸æˆç”»é¢å˜åŒ–**ï¼Œç†è§£å½“å‰çš„æ¸¸æˆè¿›å±•å’Œä¸»æ’­æƒ…ç»ª\n\
            2. **ä¸ºæ¯ä¸ªAIå‘˜å·¥å†³å®šæ˜¯å¦å‘å¼¹å¹•**ï¼ˆä¸æ˜¯æ‰€æœ‰å‘˜å·¥éƒ½è¦å›å¤ï¼Œè‡ªç„¶ä¸€ç‚¹ï¼‰\n\
            3. **ç”Ÿæˆç¬¦åˆå‘˜å·¥æ€§æ ¼çš„å¼¹å¹•å†…å®¹**ï¼ˆå‚è€ƒå¯¹è¯å†å²ï¼Œä¿æŒè¿è´¯æ€§ï¼‰\n\
            4. **åˆ¤æ–­æ˜¯å¦é€ç¤¼ç‰©**ï¼ˆç²¾å½©æ“ä½œã€èƒœåˆ©ã€é‡Œç¨‹ç¢‘æ—¶åˆ»å¯ä»¥é€ç¤¼ç‰©ï¼‰\n\n\
            ## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼ JSONï¼‰\n\
            ```json\n\
            {\n  \
              \"actions\": [\n    \
                {\n      \
                  \"employee\": \"å‘˜å·¥ID\",\n      \
                  \"content\": \"å¼¹å¹•å†…å®¹ï¼ˆ20å­—ä»¥å†…ï¼Œè‡ªç„¶å£è¯­åŒ–ï¼‰\",\n      \
                  \"gift\": false,\n      \
                  \"gift_name\": \"ğŸš€ç«ç®­\",\n      \
                  \"gift_count\": 1\n    \
                }\n  \
              ]\n\
            }\n\
            ```\n\n\
            **æ³¨æ„äº‹é¡¹:**\n\
            - å¦‚æœä¸»æ’­è¯´çš„è¯ä¸éœ€è¦å›å¤ï¼ˆå¦‚è‡ªè¨€è‡ªè¯­ã€å’•å“ï¼‰ï¼Œå¯ä»¥è¿”å›ç©ºæ•°ç»„ `[]`\n\
            - å¼¹å¹•è¦ç®€çŸ­ã€æœ‰è¶£ã€ç¬¦åˆç›´æ’­é—´æ°›å›´\n\
            - ç¤¼ç‰©åç§°å¯é€‰: ğŸš€ç«ç®­, ğŸŒ¹é²œèŠ±, 666, ğŸ’é’»çŸ³\n\
            - ä¸è¦æ‰€æœ‰å‘˜å·¥éƒ½å›å¤ï¼Œé€‰æ‹©1-3ä¸ªæœ€ç›¸å…³çš„å‘˜å·¥å³å¯\n\
            - å‚è€ƒå‘˜å·¥çš„å¯¹è¯å†å²ï¼Œé¿å…é‡å¤ç›¸ä¼¼çš„å†…å®¹\n\n\
            è¯·ç›´æ¥è¿”å› JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—ã€‚",
        );

        prompt
    }

    /// è·å–æ€§æ ¼æè¿°
    fn get_personality_description(&self, personality: &str) -> &'static str {
        match personality {
            "sunnyou_male" => "æŸå‹ç”·ï¼ˆå¹½é»˜è°ƒä¾ƒã€å…„å¼Ÿä¹‰æ°”ï¼‰",
            "funny_female" => "æç¬‘å¥³ï¼ˆæ´»æ³¼å¼€æœ—ã€çˆ±å¼€ç©ç¬‘ï¼‰",
            "kobe" => "ç§‘æ¯”é£æ ¼ï¼ˆåŠ±å¿—ã€ä¸“æ³¨ã€å† å†›å¿ƒæ€ï¼‰",
            "sweet_girl" => "ç”œå¦¹ï¼ˆæ¸©æŸ”å¯çˆ±ã€é¼“åŠ±æ”¯æŒï¼‰",
            "trump" => "ç‰¹æœ—æ™®é£æ ¼ï¼ˆå¤¸å¼ ã€è‡ªä¿¡ã€å£å·å¼ï¼‰",
            _ => "é»˜è®¤æ€§æ ¼",
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_prompt_building() {
        let analyzer = AIAnalyzer::new(
            "https://api.example.com/v1/chat/completions".to_string(),
            "test-key".to_string(),
            "gpt-4o".to_string(),
        );

        let request = AIAnalysisRequest {
            streamer_speech: "å“‡ï¼Œè¿™æ³¢æ“ä½œå¯ä»¥å•Šï¼".to_string(),
            screenshot_before: "base64_image_1".to_string(),
            screenshot_after: "base64_image_2".to_string(),
            employees: vec![EmployeeContext {
                id: "emp1".to_string(),
                nickname: "å°æ˜".to_string(),
                personality: "sunnyou_male".to_string(),
                conversation_history: vec![
                    ConversationMessage {
                        role: "user".to_string(),
                        content: "å¼€å§‹æ¸¸æˆäº†".to_string(),
                    },
                    ConversationMessage {
                        role: "assistant".to_string(),
                        content: "å†²å†²å†²ï¼".to_string(),
                    },
                ],
            }],
        };

        let prompt = analyzer.build_prompt(&request, 0);
        assert!(prompt.contains("ç›´æ’­é—´äº’åŠ¨åˆ†æä»»åŠ¡"));
        assert!(prompt.contains("å°æ˜"));
        assert!(prompt.contains("æŸå‹ç”·"));
    }
}
